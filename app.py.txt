import streamlit as st
import random
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import plotly.graph_objects as go

st.set_page_config(page_title="Self-Optimizing Workflow Agent", layout="wide")

# --------------------------
# Session State Initialization
# --------------------------
if "run" not in st.session_state:
    st.session_state.run = 0
if "decision_log" not in st.session_state:
    st.session_state.decision_log = []

# --------------------------
# Dashboard Header
# --------------------------
st.title("ðŸ¤– Self-Optimizing Workflow Orchestration Agent")
st.write("Prototype simulation of autonomous multi-agent workflow optimization")

# --------------------------
# Optimization Trigger
# --------------------------
if st.button("ðŸš€ Run Optimization Cycle"):
    st.session_state.run += 1

    # Simulate agent proposals
    latency_after = random.randint(80, 200)  # ms
    cost_after = random.randint(100, 500)    # $
    error_after = round(random.uniform(0.5, 5), 2)  # %
    throughput_after = random.randint(800, 1200)    # req/s

    # Conflict resolution (pick trade-off strategy)
    conflict_strategy = random.choice([
        "Latency-Biased",
        "Cost-Biased",
        "Balanced",
        "Error-Minimizing",
        "Throughput-Maximizing"
    ])

    # Confidence weights (simulate negotiation influence)
    weights = {
        "Latency": np.random.uniform(0.2, 1.0),
        "Cost": np.random.uniform(0.2, 1.0),
        "Error": np.random.uniform(0.2, 1.0),
        "Throughput": np.random.uniform(0.2, 1.0),
    }
    total = sum(weights.values())
    for k in weights:
        weights[k] = round(weights[k] / total, 2)

    # Log decision
    decision_entry = {
        "Run": st.session_state.run,
        "Strategy": conflict_strategy,
        "Latency_Proposal": latency_after,
        "Cost_Proposal": cost_after,
        "Error_Proposal": error_after,
        "Throughput_Proposal": throughput_after,
        "Final_Decision": f"Applied '{conflict_strategy}' trade-off",
        "Latency_Weight": weights["Latency"],
        "Cost_Weight": weights["Cost"],
        "Error_Weight": weights["Error"],
        "Throughput_Weight": weights["Throughput"],
    }
    st.session_state.decision_log.append(decision_entry)

# --------------------------
# Replay Mode
# --------------------------
st.subheader("ðŸŽ¬ Replay Mode: Step Through Runs")

if st.session_state.decision_log:
    max_run = len(st.session_state.decision_log)
    run_selected = st.slider("Select Run", 1, max_run, max_run)

    replay_df = pd.DataFrame(st.session_state.decision_log)
    current_run = replay_df[replay_df["Run"] == run_selected].iloc[0]

    st.markdown(f"**Showing Run {run_selected}:** Strategy â†’ `{current_run['Strategy']}`, Decision â†’ `{current_run['Final_Decision']}`")

    # Metrics Snapshot
    st.json({
        "Latency (ms)": current_run["Latency_Proposal"],
        "Cost ($)": current_run["Cost_Proposal"],
        "Error Rate (%)": current_run["Error_Proposal"],
        "Throughput (req/s)": current_run["Throughput_Proposal"]
    })

    # Sankey for reasoning
    fig = go.Figure(go.Sankey(
        node=dict(
            pad=15,
            thickness=20,
            line=dict(color="black", width=0.5),
            label=["Latency", "Cost", "Error", "Throughput", "Conflict Resolution", "Final Decision"],
        ),
        link=dict(
            source=[0,1,2,3, 4],
            target=[4,4,4,4, 5],
            value=[
                current_run["Latency_Weight"],
                current_run["Cost_Weight"],
                current_run["Error_Weight"],
                current_run["Throughput_Weight"],
                1
            ]
        )
    ))
    st.plotly_chart(fig, use_container_width=True)

    # Confidence Bar Chart
    conf_df = pd.DataFrame({
        "Agent": ["Latency", "Cost", "Error", "Throughput"],
        "Weight": [
            current_run["Latency_Weight"],
            current_run["Cost_Weight"],
            current_run["Error_Weight"],
            current_run["Throughput_Weight"]
        ]
    })
    st.bar_chart(conf_df.set_index("Agent"))

# --------------------------
# Time-Series Evolution
# --------------------------
st.subheader("ðŸ“ˆ Metrics Evolution Across Runs")

if st.session_state.decision_log:
    df = pd.DataFrame(st.session_state.decision_log)

    fig, ax = plt.subplots(figsize=(8,4))
    ax.plot(df["Run"], df["Latency_Proposal"], marker="o", label="Latency (ms)")
    ax.plot(df["Run"], df["Cost_Proposal"], marker="o", label="Cost ($)")
    ax.plot(df["Run"], df["Error_Proposal"], marker="o", label="Error Rate (%)")
    ax.plot(df["Run"], df["Throughput_Proposal"], marker="o", label="Throughput (req/s)")

    ax.set_xlabel("Optimization Runs")
    ax.set_ylabel("Value")
    ax.set_title("Workflow Metrics Over Time")
    ax.legend()
    ax.grid(True)

    st.pyplot(fig)
else:
    st.info("Run at least one optimization to see metrics evolution.")
